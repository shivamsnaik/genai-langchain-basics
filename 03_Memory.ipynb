{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184f82b7-9ed2-4827-9860-a6374b7437eb",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "While interacting with these models, the models usually dont store the previous conversational history. However, it is intuitive if the model keeps track of all the previous messages in order to maintain the context of the conversation.\n",
    "\n",
    "## Outline\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory\n",
    "* ConversationEntityMemory\n",
    "\n",
    "#### NOTE: Useful Links to discover other memory types\n",
    "https://python.langchain.com/docs/modules/memory/types/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3e1dc7-c1ac-47d7-9bbc-8ddfacda11ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1bb0700-cbbd-416b-a4a9-b1dcb3092bc1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6889e52-41d7-4f65-ac5c-f3919a20d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ab96465-a5e2-477d-af76-240d80d9d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0afd0826-8cef-4f6c-acbb-7e2c85e40539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a89c801d-db8a-4f5a-8fb8-1bfd3d339858",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model = llm_model)\n",
    "memory = ConversationBufferMemory( input_key = \"input\")\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = False # Shows the internal operations when set to True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4ac2c8b-acc2-42ca-940a-e214e4c92828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Shivam, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"Hi, my name is Shivam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "99d8fd2d-79d1-438d-857e-b90f71371ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"What is 1+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8722cb89-ef53-47c3-b6ac-8ef8bc16fa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Shivam.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"What is my name again?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3e34ec5e-d313-4ea1-89c8-0c3030e517e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Shivam\n",
      "AI: Hello Shivam, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name again?\n",
      "AI: Your name is Shivam.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bf402d0a-0d3b-43fd-b6c6-bc0328f8d8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Shivam\\nAI: Hello Shivam, it's nice to meet you. My name is AI. How can I assist you today?\\nHuman: What is 1+1\\nAI: The answer to 1+1 is 2.\\nHuman: What is my name again?\\nAI: Your name is Shivam.\"}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The empty curle brackets denote few of the options that can be passed.\n",
    "# If there are no options, we send empty curles.\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af65757c-2b68-4a9d-b4a0-cbf9e0a89280",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"Hi\"},\n",
    "    {\"output\": \"Whats up?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea970d14-7cf6-42bc-a359-c056eb811981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: Whats up?\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41c902d3-3059-4dc2-827f-1fcd0d43a254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi\\nAI: Whats up?'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5acd626-8199-4c95-b680-79ca43660258",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                   {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ad8bddf-f6ad-425f-a508-a3786990fdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi\\nAI: Whats up?\\nHuman: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d9dc1-fae4-4197-a132-ebf97d4b92b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ConversationBufferWindowMemory\n",
    "\n",
    "- The conversation is stored based on the window provided. Anything outside the provided window will be discarded.  \n",
    "- Pretty useful in order to just remember the most recent conversation and avoiding indefinite increase in the context provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f38d94b4-e40d-41b7-9fde-969b922294de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55aaf15e-e1d2-4524-b2fa-a8d9a53cfeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73d2d15f-5122-4ba2-823f-29e50cdaf9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                   {\"output\": \"Whats up?\"})\n",
    "\n",
    "memory.save_context({\"input\": \"Not much. Just hanging\"},\n",
    "                   {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e2e91b1-b772-4cbc-9cd7-62dc33a73900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much. Just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff68dd26-e47e-40b6-b469-cf925a309294",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4d31e34-e227-4b1c-b7cd-d27509062358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee611929-d8b1-4008-a8da-0a0ce2b97f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "402b7280-f1fa-44f3-b169-bd9348cd9838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: The answer to 1+1 is 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have access to that information. Could you please tell me your name?\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdda33b0-f6a1-4abe-8fb9-3503cd776fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is my name?\n",
      "AI: I'm sorry, I don't have access to that information. Could you please tell me your name?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I still don't have access to that information. However, I can tell you that your IP address is 123.456.789.012 and you are currently located in New York City. Is there anything else I can assist you with?\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ef510-a0ad-420e-9572-c5405b01ebe5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ConversationTokenBufferMemory\n",
    "\n",
    "The memory will limit the number of tokens. As a lot of LLM providers provide limits as per the tokens, this allows to make the calculations directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea681931-95fe-426d-adcc-497726b03b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\ichbi\\miniconda3\\envs\\llm\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\ichbi\\miniconda3\\envs\\llm\\lib\\site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ichbi\\miniconda3\\envs\\llm\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ichbi\\miniconda3\\envs\\llm\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ichbi\\miniconda3\\envs\\llm\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ichbi\\miniconda3\\envs\\llm\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ichbi\\miniconda3\\envs\\llm\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "899bcbcb-6775-4b8d-9001-c289c37aa281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8933310e-456d-4ffa-9c28-7f745bcda545",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3658d4b3-4b81-44dc-a87e-d4d05132618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996d2a9-4928-49d4-b990-29d974818ef3",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory\n",
    "\n",
    "Idea: Instead of limiting the memory based on fixed number of sentences or tokens, lets use an llm to write the summary of the conversation so far, and the summary would be the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2f96310-da35-468c-8ab1-f6089729b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95e61064-cbaa-4c84-a98d-5da34a0dcd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b80cd32b-fcbd-432f-bad0-0250c3183ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments.\"}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2299ccd6-93a4-4b41-bd37-d62d66db7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea1278d8-ceb9-48d0-be6b-38c25f18e58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the customer's interest in AI developments, I would suggest showcasing our latest natural language processing capabilities. We could demonstrate how our AI can accurately understand and respond to complex language queries, and even provide personalized recommendations based on the user's preferences. Additionally, we could highlight our AI's ability to learn and adapt over time, making it a valuable tool for businesses looking to improve their customer experience.\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00dbc44d-b8b2-4995-ad78-86146ea11098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments. The human asks what would be a good demo to show.\\nAI: Based on the customer's interest in AI developments, I would suggest showcasing our latest natural language processing capabilities. We could demonstrate how our AI can accurately understand and respond to complex language queries, and even provide personalized recommendations based on the user's preferences. Additionally, we could highlight our AI's ability to learn and adapt over time, making it a valuable tool for businesses looking to improve their customer experience.\"}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1241004e-1198-4ded-86b3-743867c1b317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments. The human asks what would be a good demo to show.\n",
      "AI: Based on the customer's interest in AI developments, I would suggest showcasing our latest natural language processing capabilities. We could demonstrate how our AI can accurately understand and respond to complex language queries, and even provide personalized recommendations based on the user's preferences. Additionally, we could highlight our AI's ability to learn and adapt over time, making it a valuable tool for businesses looking to improve their customer experience.\n",
      "Human: When should I work on LangChain?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You have a block of time scheduled for LangChain work after the morning meeting with the product team. That should give you a few hours to make progress on the project. If you need more time, we can adjust your schedule accordingly.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"When should I work on LangChain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74ec6798-3388-4434-9649-686586734aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI discuss the day's schedule, which includes a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments. The AI suggests showcasing their latest natural language processing capabilities during the demo, highlighting the AI's ability to understand and respond to complex language queries and provide personalized recommendations based on user preferences. The AI also emphasizes the AI's ability to learn and adapt over time, making it a valuable tool for businesses looking to improve their customer experience.\n",
      "Human: When should I work on LangChain?\n",
      "AI: You have a block of time scheduled for LangChain work after the morning meeting with the product team. That should give you a few hours to make progress on the project. If you need more time, we can adjust your schedule accordingly.\n",
      "Human: At what time should I work on LangChain?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You have a block of time scheduled for LangChain work starting at 10:30 AM, after the morning meeting with the product team.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"At what time should I work on LangChain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e874cd-0de3-415e-a004-3ce0ffc18625",
   "metadata": {},
   "source": [
    "## There are additional memory types that can be used in various applications:\n",
    "- **Vector Data Memory**: Stores text (from conversation or elsewhere ) in a vector database and retrieves the most relevant blocks of text.\n",
    "- **Entity Memories**: Using an LLM , it remembers details about specific entities.\n",
    "- **Traditional memory**: Storing the conversation in a conventional database (such as key-value store or SQL).\n",
    "\n",
    "**NOTE:** You can also use **multiple memories** at one time.\n",
    "E.g., <u>Conversation memory + Entity memory</u> to recall Individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8843dda-e76e-4eca-9cf1-c9bf966e35c8",
   "metadata": {},
   "source": [
    "## Conversation Memory + Entity Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e8912531-cdc4-4e36-a3db-90c40a92406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationEntityMemory, \\\n",
    "ConversationSummaryBufferMemory, CombinedMemory\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "65623b8a-66f4-4db7-ae71-ddb875d5205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationEntityMemory(llm = llm, input_key=\"input\", chat_history_key=\"chat_history_lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7ca6315c-348f-48b9-a627-afbeac4e9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. \\\n",
    "The AI is talkative and provides lots of specific details from its context. If the AI does \\\n",
    "not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Summary of conversation:\n",
    "{chat_history_lines}\n",
    "Entities\n",
    "{entities}\n",
    "Human: {input}\n",
    "AI:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "387d95df-3641-4e28-b0bd-c72aeff18619",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    input_variables = [\"chat_history_lines\", \"input\", \"entities\"],\n",
    "    template = _DEFAULT_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ff99a211-b70e-4fdc-9844-2f1f6e2729c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entities', 'chat_history_lines']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.memory_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a86664df-9098-418b-af4e-74fc42530b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm=llm, verbose=True, memory=memory, prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "97f0150a-083e-4f04-b284-67cbb821b051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "Human: Hi\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: What are you doing?\n",
      "AI: I am currently processing and analyzing data to provide accurate and helpful responses to your inquiries. Is there anything specific you would like me to assist you with?\n",
      "Human: My name is Shivam Naik\n",
      "AI: Yes, I am aware of that, Shivam Naik. Is there anything else you would like me to assist you with?\n",
      "Entities\n",
      "{}\n",
      "Human: Hi\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "51d2a53e-6979-4c8d-bfb5-f0dadfd8ddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "Human: What are you doing?\n",
      "AI: I am currently processing and analyzing data to provide accurate and helpful responses to your inquiries.\n",
      "Human: My name is Shivam Naik\n",
      "AI: Nice to meet you, Shivam Naik! How can I assist you today?\n",
      "Human: Hi\n",
      "AI: Hello! How can I assist you today?\n",
      "Entities\n",
      "{}\n",
      "Human: What are you doing?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am currently processing and analyzing data to provide accurate and helpful responses to your inquiries. Is there anything specific you would like me to assist you with?'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"What are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a8fb30dc-5944-45c4-ba7f-91f471ea713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "Human: My name is Shivam Naik\n",
      "AI: Nice to meet you, Shivam Naik! How can I assist you today?\n",
      "Human: Hi\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: What are you doing?\n",
      "AI: I am currently processing and analyzing data to provide accurate and helpful responses to your inquiries. Is there anything specific you would like me to assist you with?\n",
      "Entities\n",
      "{'Shivam Naik': 'Shivam Naik is the name of the human interacting with the AI assistant.'}\n",
      "Human: My name is Shivam Naik\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, I am aware of that, Shivam Naik. Is there anything else you would like me to assist you with?'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"My name is Shivam Naik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "199b4c0a-4429-4384-9ae5-d2a7e0d8899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "Human: What are you doing?\n",
      "AI: I am currently processing and analyzing data to provide accurate and helpful responses to your inquiries. Is there anything specific you would like me to assist you with?\n",
      "Human: My name is Shivam Naik\n",
      "AI: Yes, I am aware of that, Shivam Naik. Is there anything else you would like me to assist you with?\n",
      "Human: Hi\n",
      "AI: Hello! How can I assist you today?\n",
      "Entities\n",
      "{}\n",
      "Human: How many people do you know?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As an AI, I have access to a vast amount of information and data, but I do not \"know\" people in the traditional sense. However, I can provide information on the number of registered users or accounts on various platforms or databases if that is what you are looking for.'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"How many people do you know?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "73dc201f-1da1-4721-b358-079c8d2feb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Summary of conversation:\n",
      "Human: Hi\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: How many people do you know?\n",
      "AI: As an AI, I have access to a vast amount of information and data, but I do not \"know\" people in the traditional sense. However, I can provide information on the number of registered users or accounts on various platforms or databases if that is what you are looking for.\n",
      "Human: Who am I?\n",
      "AI: You are Shivam Naik, as you previously mentioned.\n",
      "Entities\n",
      "{'Shivam Naik': 'Shivam Naik is the name of the human interacting with the AI assistant.'}\n",
      "Human: Who am I?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You are Shivam Naik, as you previously mentioned.'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(input = \"Who am I?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95153f21-629f-4fc8-ad15-2cac1ca2bbce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
